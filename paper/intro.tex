
The spread of misinformation on social media poses substantial challenges to public discourse and collective decision-making. While exposure and diffusion dynamics have been extensively studied—particularly on platforms such as Facebook, where recent evidence suggests a decline in the circulation of false content \citep{allcott2019trends}, much less is known about alternative communication environments like Telegram. Unlike Facebook, Twitter/X, and other algorithm-driven platforms, Telegram does not rely on a personalized recommendation system. Information spreads primarily through channels, groups, and direct forwarding, rather than through algorithmic curation. This absence of recommendation algorithms provides a cleaner environment to observe how misinformation propagates, as diffusion is less confounded by opaque platform-level ranking mechanisms.

In this study, we aim to investigate how this distinct institutional setting shapes the propagation of misinformation. A central question guides our analysis: what motivates individuals to share false information, and how do their social relationships and reputational concerns influence this behavior?

Our work builds upon the economic foundations of information behavior. First, reputational concerns have long been recognized as fundamental drivers of human behavior: individuals care about how their actions affect how they are perceived by others \citep{benabou2006incentives, benabou2011identity}. This logic directly parallels models of media behavior, where information senders strategically choose what to transmit because audiences update beliefs about the sender's credibility. In particular, the reputation-driven framework of \citet{gentzkow2006media}—in which media outlets condition reporting on how it affects perceived accuracy—serves as a microfoundational motivation for how we model reputation among individuals in messaging platforms.

Second, empirical research finds that news sharing is shaped not only by beliefs but also by social approval, status motives, and identity-driven incentives \citep{talwar2020fake, wu2025motivations, vellani2024motives}. Evidence from WhatsApp further shows that reputational mechanisms matter: forwarded-message labels influence perceptions of credibility and willingness to share \citep{tandoc2022forwarded}, and exposure to fact-checking reduces subsequent forwarding \citep{reis2020whatsapp}. Work on Telegram additionally documents high-concentration misinformation ecosystems in channels shaped by tight-knit community norms \citep{herasimenka2022telegram}.

Finally, our approach is closely related to recent advances in misinformation modeling. \citet{acemoglu2024misinformation} develop an equilibrium framework in which agents weigh social utility against the risk of reputational loss (“being called out”), generating endogenous filter bubbles. Dynamic network approaches such as \citet{yilmaz2022deep} highlight how strategic interactions and influence-maximizing dynamics shape diffusion on evolving topologies.

While these studies provide deep insight into misinformation and strategic behavior, most focus on equilibrium characterizations, platform-level incentives, or adversarial spread. Our research departs from this by explicitly modeling multi-round diffusion where an agent’s reputation and subjective beliefs evolve endogenously and shape future propagation. We focus on three primary questions: 


\begin{enumerate}
    \item How does an agent's subjective belief regarding the veracity of a message, coupled with the value they place on their personal reputation, affect the initial propensity and subsequent widespread dissemination of misinformation?
    \item In a dynamic setting, how is misinformation contained within local neighborhoods, or conversely, how is it allowed to spread more widely across the network upon multiple rounds of agents updating their information and actions?
    \item How does the velocity and final extent of misinformation spread vary across different, structured topologies of social networks, such as scale-free, random, or small-world networks?
\end{enumerate}

To answer these research questions, our strategy employs two  components: (i) a formalization of the agents' forwarding and updating decisions based on game theory, and (ii) large-scale agent-based simulations designed to trace message diffusion across social networks. Specifically, we focus on platforms such as WhatsApp and Telegram, where forwarding behavior plays a central role in information propagation. We will conduct these simulations across a spectrum of network topologies and agent types to produce quantitative results on the rate of spread and provide a comprehensive description of how information contamination evolves in various structural and behavioral scenarios.